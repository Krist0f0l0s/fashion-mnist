{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.035333</td>\n",
       "      <td>0.101933</td>\n",
       "      <td>0.247967</td>\n",
       "      <td>0.411467</td>\n",
       "      <td>0.805767</td>\n",
       "      <td>2.198283</td>\n",
       "      <td>5.682000</td>\n",
       "      <td>...</td>\n",
       "      <td>34.625400</td>\n",
       "      <td>23.300683</td>\n",
       "      <td>16.588267</td>\n",
       "      <td>17.869433</td>\n",
       "      <td>22.814817</td>\n",
       "      <td>17.911483</td>\n",
       "      <td>8.520633</td>\n",
       "      <td>2.753300</td>\n",
       "      <td>0.855517</td>\n",
       "      <td>0.07025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.872305</td>\n",
       "      <td>0.094689</td>\n",
       "      <td>0.271011</td>\n",
       "      <td>1.222324</td>\n",
       "      <td>2.452871</td>\n",
       "      <td>4.306912</td>\n",
       "      <td>5.836188</td>\n",
       "      <td>8.215169</td>\n",
       "      <td>14.093378</td>\n",
       "      <td>23.819481</td>\n",
       "      <td>...</td>\n",
       "      <td>57.545242</td>\n",
       "      <td>48.854427</td>\n",
       "      <td>41.979611</td>\n",
       "      <td>43.966032</td>\n",
       "      <td>51.830477</td>\n",
       "      <td>45.149388</td>\n",
       "      <td>29.614859</td>\n",
       "      <td>17.397652</td>\n",
       "      <td>9.356960</td>\n",
       "      <td>2.12587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>170.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              label        pixel1        pixel2        pixel3        pixel4  \\\n",
       "count  60000.000000  60000.000000  60000.000000  60000.000000  60000.000000   \n",
       "mean       4.500000      0.000900      0.006150      0.035333      0.101933   \n",
       "std        2.872305      0.094689      0.271011      1.222324      2.452871   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        2.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        4.500000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        7.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        9.000000     16.000000     36.000000    226.000000    164.000000   \n",
       "\n",
       "             pixel5        pixel6        pixel7        pixel8        pixel9  \\\n",
       "count  60000.000000  60000.000000  60000.000000  60000.000000  60000.000000   \n",
       "mean       0.247967      0.411467      0.805767      2.198283      5.682000   \n",
       "std        4.306912      5.836188      8.215169     14.093378     23.819481   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max      227.000000    230.000000    224.000000    255.000000    254.000000   \n",
       "\n",
       "       ...      pixel775      pixel776      pixel777      pixel778  \\\n",
       "count  ...  60000.000000  60000.000000  60000.000000  60000.000000   \n",
       "mean   ...     34.625400     23.300683     16.588267     17.869433   \n",
       "std    ...     57.545242     48.854427     41.979611     43.966032   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "75%    ...     58.000000      9.000000      0.000000      0.000000   \n",
       "max    ...    255.000000    255.000000    255.000000    255.000000   \n",
       "\n",
       "           pixel779      pixel780      pixel781      pixel782      pixel783  \\\n",
       "count  60000.000000  60000.000000  60000.000000  60000.000000  60000.000000   \n",
       "mean      22.814817     17.911483      8.520633      2.753300      0.855517   \n",
       "std       51.830477     45.149388     29.614859     17.397652      9.356960   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max      255.000000    255.000000    255.000000    255.000000    255.000000   \n",
       "\n",
       "          pixel784  \n",
       "count  60000.00000  \n",
       "mean       0.07025  \n",
       "std        2.12587  \n",
       "min        0.00000  \n",
       "25%        0.00000  \n",
       "50%        0.00000  \n",
       "75%        0.00000  \n",
       "max      170.00000  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# załaduj dane\n",
    "train = pd.read_csv(\"./data/fashion-mnist_train.csv\")\n",
    "test = pd.read_csv(\"./data/fashion-mnist_test.csv\")\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "z powyższej tabeli wynika, że mamy 10 etykiet\n",
    "<br>\n",
    "Znaczenie etykiet:\n",
    "* 0 \tT-shirt/top\n",
    "* 1 \tTrouser\n",
    "* 2 \tPullover\n",
    "* 3 \tDress\n",
    "* 4 \tCoat\n",
    "* 5 \tSandal\n",
    "* 6 \tShirt\n",
    "* 7 \tSneaker\n",
    "* 8 \tBag\n",
    "* 9 \tAnkle boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['T-shirt\\top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# podziel danych na do nauki i testu\n",
    "x_train, y_train = train.loc[:, train.columns != 'label']/255, train['label']\n",
    "x_test, y_test = test.loc[:, test.columns != 'label']/255, test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x288d3159520>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# wizualizacja danych\n",
    "n=10\n",
    "print(y_train[n])\n",
    "plt.imshow(x_train.loc[n].values.reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.001, # minimium amount of change to count as an improvement\n",
    "    patience=20, # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - 558us/step - accuracy: 0.8838 - loss: 0.3240\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.32402345538139343, 0.8838000297546387]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zwykła sieć neuronowa, 1 warstwa ukryta\n",
    "\n",
    "model1 = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Input((784,)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "model1.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss_fn,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history1 = model1.fit(x_train, y_train, validation_split=0.25, epochs=100, verbose=0, callbacks=[early_stopping])\n",
    "model1.evaluate(x_test,  y_test, verbose=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 20\u001b[0m\n\u001b[0;32m     12\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mSparseCategoricalCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     14\u001b[0m model4\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m     15\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[0;32m     16\u001b[0m     loss\u001b[38;5;241m=\u001b[39mloss_fn,\n\u001b[0;32m     17\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     18\u001b[0m )\n\u001b[1;32m---> 20\u001b[0m history4 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel4\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m model4\u001b[38;5;241m.\u001b[39mevaluate(x_test,  y_test, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m) \n",
      "File \u001b[1;32mc:\\Users\\kbols\\Desktop\\fashion-mnist\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\kbols\\Desktop\\fashion-mnist\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[1;32mc:\\Users\\kbols\\Desktop\\fashion-mnist\\.venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\kbols\\Desktop\\fashion-mnist\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\kbols\\Desktop\\fashion-mnist\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\kbols\\Desktop\\fashion-mnist\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kbols\\Desktop\\fashion-mnist\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\kbols\\Desktop\\fashion-mnist\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\kbols\\Desktop\\fashion-mnist\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\kbols\\Desktop\\fashion-mnist\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\kbols\\Desktop\\fashion-mnist\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# zwykła sieć neuronowa, 4 warstwy ukryta\n",
    "model4 = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Input((784,)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "model4.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss_fn,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history4 = model4.fit(x_train, y_train, validation_split=0.25, epochs=100, verbose=0, callbacks=[early_stopping])\n",
    "model4.evaluate(x_test,  y_test, verbose=2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zwiększając głębokość sieci, nie uzsykaliśmy zwiększenia dokładności<br>W obu przypadkach dokładność ~88%, dosyć niska"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zmiana kształtu danych pod sieć konwolucyjną\n",
    "x_train_cnn = x_train.values.reshape((60000, 28,28))\n",
    "x_test_cnn = x_test.values.reshape((10000, 28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.7449 - loss: 0.7377 - val_accuracy: 0.8467 - val_loss: 0.4097\n",
      "Epoch 2/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.8786 - loss: 0.3395 - val_accuracy: 0.8857 - val_loss: 0.3208\n",
      "Epoch 3/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.8925 - loss: 0.2947 - val_accuracy: 0.8913 - val_loss: 0.3028\n",
      "Epoch 4/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.8981 - loss: 0.2778 - val_accuracy: 0.9021 - val_loss: 0.2731\n",
      "Epoch 5/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9130 - loss: 0.2333 - val_accuracy: 0.9025 - val_loss: 0.2687\n",
      "Epoch 6/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9208 - loss: 0.2152 - val_accuracy: 0.9095 - val_loss: 0.2565\n",
      "Epoch 7/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9290 - loss: 0.1954 - val_accuracy: 0.9087 - val_loss: 0.2544\n",
      "Epoch 8/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9352 - loss: 0.1779 - val_accuracy: 0.9106 - val_loss: 0.2520\n",
      "Epoch 9/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9439 - loss: 0.1536 - val_accuracy: 0.9125 - val_loss: 0.2542\n",
      "Epoch 10/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9456 - loss: 0.1466 - val_accuracy: 0.9163 - val_loss: 0.2534\n",
      "Epoch 11/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9548 - loss: 0.1258 - val_accuracy: 0.9183 - val_loss: 0.2504\n",
      "Epoch 12/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.9568 - loss: 0.1195 - val_accuracy: 0.9149 - val_loss: 0.2666\n",
      "Epoch 13/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9621 - loss: 0.1038 - val_accuracy: 0.9145 - val_loss: 0.2672\n",
      "Epoch 14/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9644 - loss: 0.0967 - val_accuracy: 0.9086 - val_loss: 0.2965\n",
      "Epoch 15/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9702 - loss: 0.0842 - val_accuracy: 0.9207 - val_loss: 0.2674\n",
      "Epoch 16/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9741 - loss: 0.0716 - val_accuracy: 0.9188 - val_loss: 0.2953\n",
      "Epoch 17/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9756 - loss: 0.0658 - val_accuracy: 0.9169 - val_loss: 0.3109\n",
      "Epoch 18/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9805 - loss: 0.0565 - val_accuracy: 0.9188 - val_loss: 0.3134\n",
      "Epoch 19/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9826 - loss: 0.0495 - val_accuracy: 0.9152 - val_loss: 0.3343\n",
      "Epoch 20/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9844 - loss: 0.0448 - val_accuracy: 0.9173 - val_loss: 0.3528\n",
      "Epoch 21/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9872 - loss: 0.0357 - val_accuracy: 0.9203 - val_loss: 0.3390\n",
      "Epoch 22/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9889 - loss: 0.0316 - val_accuracy: 0.9209 - val_loss: 0.3652\n",
      "Epoch 23/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9868 - loss: 0.0404 - val_accuracy: 0.9165 - val_loss: 0.3905\n",
      "Epoch 24/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9912 - loss: 0.0267 - val_accuracy: 0.9207 - val_loss: 0.3866\n",
      "Epoch 25/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9918 - loss: 0.0236 - val_accuracy: 0.9201 - val_loss: 0.3974\n",
      "Epoch 26/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9924 - loss: 0.0240 - val_accuracy: 0.9204 - val_loss: 0.4247\n",
      "Epoch 27/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9952 - loss: 0.0166 - val_accuracy: 0.9175 - val_loss: 0.4554\n",
      "Epoch 28/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9896 - loss: 0.0280 - val_accuracy: 0.9142 - val_loss: 0.4550\n",
      "Epoch 29/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9930 - loss: 0.0198 - val_accuracy: 0.9145 - val_loss: 0.4817\n",
      "Epoch 30/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9962 - loss: 0.0124 - val_accuracy: 0.9166 - val_loss: 0.4622\n",
      "Epoch 31/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9913 - loss: 0.0253 - val_accuracy: 0.9171 - val_loss: 0.4864\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9168 - loss: 0.2424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.23217204213142395, 0.921500027179718]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input((28,28,1)),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), padding='same', activation=tf.nn.relu),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "model_cnn.compile(optimizer='adam', metrics=['accuracy'], loss=loss_fn)\n",
    "\n",
    "history = model_cnn.fit(x_train_cnn, y_train, batch_size=128, epochs=100, validation_split=0.25, callbacks=[early_stopping])\n",
    "model_cnn.evaluate(x_test_cnn, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cnn radzi sobie dużo lepiej, dokładność ~92%, ale występuje overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "accuracy = history.history['accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "passed = len(loss)\n",
    "t = np.arange(0, passed, 1)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(t, loss)\n",
    "ax.plot(t, val_loss)\n",
    "ax.set(xlim=(0,passed), xticks=t, xticklabels=t+1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Czytanki\n",
    "* https://medium.com/@learnwithwhiteboard_digest/8-tips-on-how-to-choose-neural-network-architecture-e50590e99ab1\n",
    "* https://arxiv.org/pdf/1206.5533\n",
    "* https://machinelearningmastery.com/using-dropout-regularization-in-pytorch-models/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
